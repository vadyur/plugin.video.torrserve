#!/usr/bin/python
# -*- coding: utf-8 -*-

import os
try:
    import xbmc, xbmcaddon
except: 
    pass
#-------------------------------
import socket
socket.setdefaulttimeout(30)

import sys
if sys.version_info >= (3, 0):
    from urllib import request as urllib_request
    from urllib.parse import urlencode
else:
    import urllib2 as urllib_request
    from urllib import urlencode


#-----------------------------------------

siteUrl = ''
try:
    __settings__ = xbmcaddon.Addon()
    siteUrl = __settings__.getSetting('nnmclub_url')
except: 
    pass
if siteUrl == "": 
    siteUrl = 'nnmclub.to'
httpSiteUrl = 'http://' + siteUrl


def ru(x):
    if sys.version_info >= (3, 0):
        return x
    else:
        return unicode(x,'utf8', 'ignore')
def xt(x):
    return xbmc.translatePath(x)
def rt(x):
    L=[('&quot;','"'), ('&amp;',"&"),('&#133;','…'),('&#38;','&'),('&#34;','"'), ('&#39;','"'), ('&#145;','"'), ('&#146;','"'), ('&#147;','“'), ('&#148;','”'), ('&#149;','•'), ('&#150;','–'), ('&#151;','—'), ('&#152;','?'), ('&#153;','™'), ('&#154;','s'), ('&#155;','›'), ('&#156;','?'), ('&#157;',''), ('&#158;','z'), ('&#159;','Y'), ('&#160;',''), ('&#161;','?'), ('&#162;','?'), ('&#163;','?'), ('&#164;','¤'), ('&#165;','?'), ('&#166;','¦'), ('&#167;','§'), ('&#168;','?'), ('&#169;','©'), ('&#170;','?'), ('&#171;','«'), ('&#172;','¬'), ('&#173;',''), ('&#174;','®'), ('&#175;','?'), ('&#176;','°'), ('&#177;','±'), ('&#178;','?'), ('&#179;','?'), ('&#180;','?'), ('&#181;','µ'), ('&#182;','¶'), ('&#183;','·'), ('&#184;','?'), ('&#185;','?'), ('&#186;','?'), ('&#187;','»'), ('&#188;','?'), ('&#189;','?'), ('&#190;','?'), ('&#191;','?'), ('&#192;','A'), ('&#193;','A'), ('&#194;','A'), ('&#195;','A'), ('&#196;','A'), ('&#197;','A'), ('&#198;','?'), ('&#199;','C'), ('&#200;','E'), ('&#201;','E'), ('&#202;','E'), ('&#203;','E'), ('&#204;','I'), ('&#205;','I'), ('&#206;','I'), ('&#207;','I'), ('&#208;','?'), ('&#209;','N'), ('&#210;','O'), ('&#211;','O'), ('&#212;','O'), ('&#213;','O'), ('&#214;','O'), ('&#215;','?'), ('&#216;','O'), ('&#217;','U'), ('&#218;','U'), ('&#219;','U'), ('&#220;','U'), ('&#221;','Y'), ('&#222;','?'), ('&#223;','?'), ('&#224;','a'), ('&#225;','a'), ('&#226;','a'), ('&#227;','a'), ('&#228;','a'), ('&#229;','a'), ('&#230;','?'), ('&#231;','c'), ('&#232;','e'), ('&#233;','e'), ('&#234;','e'), ('&#235;','e'), ('&#236;','i'), ('&#237;','i'), ('&#238;','i'), ('&#239;','i'), ('&#240;','?'), ('&#241;','n'), ('&#242;','o'), ('&#243;','o'), ('&#244;','o'), ('&#245;','o'), ('&#246;','o'), ('&#247;','?'), ('&#248;','o'), ('&#249;','u'), ('&#250;','u'), ('&#251;','u'), ('&#252;','u'), ('&#253;','y'), ('&#254;','?'), ('&#255;','y'), ('&laquo;','"'), ('&raquo;','"'), ('&nbsp;',' ')]
    for i in L:
        x=x.replace(i[0], i[1])
    return x

def mfindal(http, ss, es):
    L=[]
    while http.find(es)>0:
        s=http.find(ss)
        e=http.find(es)
        i=http[s:e]
        L.append(i)
        http=http[e+2:]
    return L

def mfind(t,s,e):
    n = t.find(s)
    if n == -1: return ''
    r=t[n+len(s):]
    f = r.find(e)
    if f == -1: return ''
    r2=r[:f]
    return r2

def rulower(str):
    str=str.strip()
    str=xt(str).lower()
    str=str.replace('Й','й')
    str=str.replace('Ц','ц')
    str=str.replace('У','у')
    str=str.replace('К','к')
    str=str.replace('Е','е')
    str=str.replace('Н','н')
    str=str.replace('Г','г')
    str=str.replace('Ш','ш')
    str=str.replace('Щ','щ')
    str=str.replace('З','з')
    str=str.replace('Х','х')
    str=str.replace('Ъ','ъ')
    str=str.replace('Ф','ф')
    str=str.replace('Ы','ы')
    str=str.replace('В','в')
    str=str.replace('А','а')
    str=str.replace('П','п')
    str=str.replace('Р','р')
    str=str.replace('О','о')
    str=str.replace('Л','л')
    str=str.replace('Д','д')
    str=str.replace('Ж','ж')
    str=str.replace('Э','э')
    str=str.replace('Я','я')
    str=str.replace('Ч','ч')
    str=str.replace('С','с')
    str=str.replace('М','м')
    str=str.replace('И','и')
    str=str.replace('Т','т')
    str=str.replace('Ь','ь')
    str=str.replace('Б','б')
    str=str.replace('Ю','ю')
    return str

def lower(s):
    try:
        s=s.decode('utf-8')
    except: 
        pass
    try:
        s=s.decode('windows-1251')
    except: 
        pass
    s=s.lower().encode('utf-8')
    return s


def GET(target, referer='', post=None):
    try:
        req = urllib_request.Request(url = target, data = post)
        req.add_header('User-Agent', 'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1) ; .NET CLR 1.1.4322; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729; .NET4.0C)')
        req.add_header('accept-encoding', 'gzip')
        resp = urllib_request.urlopen(req)
        if resp.info().get('Content-Encoding') == 'gzip':
            from io import StringIO
            import gzip
            buf = StringIO(resp.read())
            f = gzip.GzipFile(fileobj=buf)
            http = f.read()
        else:
            http=resp.read()
        resp.close()
        return http
    except Exception as e:
        print(e)

def POST(target, post=None, referer='', cookie=False):
    try:
        req = urllib_request.Request(url = target, data = post)
        req.add_header('User-Agent', 'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1) ; .NET CLR 1.1.4322; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729; .NET4.0C)')
        req.add_header('Referer', referer)
        #req.add_header('X-Requested-With', 'XMLHttpRequest')
        if cookie:
            cookiepath = os.path.join(xbmc.translatePath('special://temp/'), 'nnmclub_tc.txt')
            import http.cookiejar
            jar = http.cookiejar.LWPCookieJar(cookiepath)
            if os.path.isfile(cookiepath): jar.load()
            opener = urllib_request.build_opener(urllib_request.HTTPCookieProcessor(jar))
            resp = opener.open(req)
        else:
            resp = urllib_request.urlopen(req)
        http = resp.read()
        resp.close()
        try:
            http = http.decode(resp.info().get('Content-Type').split('charset=')[1], 'replace')
            http = http.encode('utf8')
        except: 
            pass
        if cookie: 
            jar.save()
        return http
    except Exception as e:
        return ('')

def get_list(hp):#, info):
    body = mfind(hp, '<tbody>','</tbody>')
    L=mfindal(body, '<tr class="prow', '</tr>')
    L2=[]
    for i in L: #[:2]:
        for s in i.splitlines():
            if 'td title="" class=' in s:
                ttl = mfind(s, '<b>', '<')
                ttd = mfind(s, 'gensmall opened">', '</span')
            if '"nowrap" class="gensmall"><u>' in s:
                size=mfind(s, '</u>', '</td>').replace('&nbsp;', ' ').replace(',','.').strip()
            if 'title="Seeders"' in s:
                seeds = mfind(s, '<b>', '<')
            if 'download.php?id=' in s:
                url = mfind(s, 'href="','" rel')
        curl=httpSiteUrl+'/forum/'+url
        if ttd: ttl = ttl+' '+ttd
        itm ={"sids":seeds,"size":size, "title":ttl,"url":curl}#xt()
        L2.append(itm)
    
    return L2

class Tracker(object):
    def __init__(self):
        pass

    def Search(self, info):
        #print '====== wriza.top ====='
        #tmc = time.strftime('%d%y%m')
        t = info['originaltitle']
        if isinstance(t, str): 
            t = t.decode('utf8')
        string_to_search_converted = t.replace(' ', '+').encode('cp1251')

        payload = {
            'prev_sd' : 0,
            'prev_a' : 0,
            'prev_my' : 0,
            'prev_n' : 0,
            'prev_shc' : 0, # показывать колонку Категория
            'prev_shf' : 1, # показывать колонку Форум
            'prev_sha' : 1, # показывать колонку Автор
            'prev_shs' : 0, # показывать колонку Скорость
            'prev_shr' : 0, # показывать колонку Рейтинг
            'prev_sht' : 0, # показывать колонку Спасибо
            'f[]' : -1, # категории, где искать. '-1' = 'все имеющиеся'
            'o' : 1, # 1 - зарегистрирован, 4 - скачан, 7 - размер
            's' : 2, # 1 - по возрастанию, 2 - по убыванию
            'tm' : -1, # 30 - посл месяц, 7 - за посл неделю, -1 - за все время
            'shf' : 1,
            'sha' : 1,
            'ta' : -1,
            'sns' : -1,
            'sds' : -1,
            'nm' : string_to_search_converted,
            'pn' : '',
            'submit' : 'Поиск'
        }

        url=httpSiteUrl+'/forum/tracker.php'
        post=urlencode(payload)
        hp=POST(url, post)
        Lout=get_list(hp) #, info)
        
        return Lout

    def Login(self, username, password, redirect=None, code=None):
        payload = {'username': username, 'password': password, 'autologin':'on',
                'redirect':'index.php', 'login':'Вход'}
        if redirect: payload['redirect'] = redirect
        if code: payload['code'] = code
        post = urlencode(payload)
        hp = POST(httpSiteUrl+'/forum/login.php', post, cookie=True)
        return hp

    def Query(self, query):
        try:
            return self.Search({'originaltitle': query})
        except Exception as e:
            print(e)
            return []

if __name__ == '__main__':
    print (Tracker().Query('гамбит'))
