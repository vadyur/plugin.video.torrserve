#!/usr/bin/python
# -*- coding: utf-8 -*-

#-------------------------------
import urllib, time, random
#from time import gmtime, strftime 
#from urlparse import urlparse 
import socket
socket.setdefaulttimeout(30)

from . import xt

#-----------------------------------------

import sys
if sys.version_info >= (3, 0):
    from urllib import request as urllib_request
    from urllib.parse import urlencode
else:
    import urllib2 as urllib_request
    from urllib import urlencode


siteUrl = '232009.wriza.top'
httpSiteUrl = 'http://' + siteUrl


# - ====================================== antizapret ====================================================
#import time, cookielib
#sid_file = os.path.join(xbmc.translatePath('special://temp/'), 'vpn.sid')
#cj = cookielib.FileCookieJar(sid_file) 
#hr  = urllib_request.HTTPCookieProcessor(cj) 
#Lthread=[]


def mfindal(http, ss, es):
	L=[]
	while http.find(es)>0:
		s=http.find(ss)
		e=http.find(es)
		i=http[s:e]
		L.append(i)
		http=http[e+2:]
	return L

def mfind(t,s,e):
	r=t[t.find(s)+len(s):]
	r2=r[:r.find(e)]
	return r2

def rulower(str):
	str=str.strip()
	str=xt(str).lower()
	str=str.replace('Й','й')
	str=str.replace('Ц','ц')
	str=str.replace('У','у')
	str=str.replace('К','к')
	str=str.replace('Е','е')
	str=str.replace('Н','н')
	str=str.replace('Г','г')
	str=str.replace('Ш','ш')
	str=str.replace('Щ','щ')
	str=str.replace('З','з')
	str=str.replace('Х','х')
	str=str.replace('Ъ','ъ')
	str=str.replace('Ф','ф')
	str=str.replace('Ы','ы')
	str=str.replace('В','в')
	str=str.replace('А','а')
	str=str.replace('П','п')
	str=str.replace('Р','р')
	str=str.replace('О','о')
	str=str.replace('Л','л')
	str=str.replace('Д','д')
	str=str.replace('Ж','ж')
	str=str.replace('Э','э')
	str=str.replace('Я','я')
	str=str.replace('Ч','ч')
	str=str.replace('С','с')
	str=str.replace('М','м')
	str=str.replace('И','и')
	str=str.replace('Т','т')
	str=str.replace('Ь','ь')
	str=str.replace('Б','б')
	str=str.replace('Ю','ю')
	return str

def lower(s):
	try:s=s.decode('utf-8')
	except: pass
	try:s=s.decode('windows-1251')
	except: pass
	s=s.lower().encode('utf-8')
	return s


def GET(target, referer='', post=None):
	try:
		req = urllib_request.Request(url = target, data = post)
		req.add_header('User-Agent', 'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1) ; .NET CLR 1.1.4322; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729; .NET4.0C)')
		req.add_header('accept-encoding', 'gzip')
		resp = urllib_request.urlopen(req)
		if resp.info().get('Content-Encoding') == 'gzip':
			from io import StringIO
			import gzip
			buf = StringIO(resp.read())
			f = gzip.GzipFile(fileobj=buf)
			http = f.read()
		else:
			http=resp.read()
		resp.close()
		return http
	except Exception as e:
		print (e)

def POST(target, post=None, referer=''):
	try:
		req = urllib_request.Request(url = target, data = post)
		req.add_header('User-Agent', 'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1) ; .NET CLR 1.1.4322; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729; .NET4.0C)')
		req.add_header('Referer', referer)
		#req.add_header('X-Requested-With', 'XMLHttpRequest')
		resp = urllib_request.urlopen(req)
		http = resp.read()
		resp.close()
#		print http
		return http
	except Exception as e:
		print (e)
		return ''

def get_list(hp):#, info):
	#title=info['title']
	#print '== get_list =='
	#print len(hp)
	L=mfindal(hp, '<td class="row4 med tLeft">', '<td class="row4 small nowrap" style')
	#print len(L)
	L2=[]
	for i in L:
		#print '======='
		for s in i.splitlines():
			if 'genmed tLink' in s: 
				tid = mfind(s, '/torrent/', '">')
				ttl = mfind(s, '<b>', '<')
			if 'small tr-dl' in s: 
				size=mfind(s, '">', '<').replace('&nbsp;', ' ')
			if 'row4 seedmed' in s: 
				seeds = mfind(s, '<b>', '<')
		curl='https://d.wriza.top/download/'+tid
		#print tid
		#print ttl
		#print size
		#print seeds
		ttl = ttl.replace('&#039;',"'")
		itm ={"sids":seeds,"size":size, "title":ttl,"url":curl}#xt()
#		if int(seeds) > 5:
		L2.append(itm)
	
	return L2



class Tracker:
	def __init__(self):
		pass

	def Search(self, info):
		#print '====== wriza.top ====='
		tmc = time.strftime('%d%y%m')
		t=urllib.quote_plus(info['originaltitle'])
		url='https://'+tmc+'.wriza.top/ser.php'#232009
		post='query='+t
		#print post
		hp=POST(url, post)
		Lout=get_list(hp)#, info)
		
		return Lout

	def Query(self, query):
		try:
			f = query.find("'")
			if f > -1: query = query[:f]+query[f+2:]
#			print query
			return self.Search({'originaltitle': query})
		except Exception as e:
			print (e)
			return []

if __name__ == '__main__':
#	print Tracker().Query("Queen's Gambit")
	print (Tracker().Query("гамбит"))
